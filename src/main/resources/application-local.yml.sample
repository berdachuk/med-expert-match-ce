# Local profile: same settings as Docker stack (DB on localhost:5433, LLM on 127.0.0.1:1234)
# Activate with: --spring.profiles.active=local or SPRING_PROFILES_ACTIVE=local

spring:
  datasource:
    url: jdbc:postgresql://localhost:5433/medexpertmatch
    username: medexpertmatch
    password: <your password>
  ai:
    custom:
      chat:
        provider: openai
        base-url: http://127.0.0.1:1234
        api-key: llm-studio
        model: medgemma-1.5-4b-it@q4_k_m
        temperature: 0.7
        max-tokens: 6000
      embedding:
        provider: openai
        base-url: http://127.0.0.1:1234
        api-key: llm-studio
        model: text-embedding-nomic-embed-text-v1.5
        dimensions: 768
      reranking:
        provider: openai
        base-url: http://127.0.0.1:1234
        api-key: llm-studio
        model: medgemma-1.5-4b-it@q4_k_m
        temperature: 0.1
      tool-calling:
        provider: openai
        base-url: http://127.0.0.1:1234
        api-key: llm-studio
        model: qwen/qwen3-4b-2507
        temperature: 0.7
        max-tokens: 4096

server:
  port: 8080

medexpertmatch:
  skills:
    enabled: true
    directory: .claude/skills
    extra-directory: ""
  llm:
    chat:
      max-concurrent-calls: 1
    embedding:
      max-concurrent-calls: 1
    reranking:
      max-concurrent-calls: 1
    tool-calling:
      max-concurrent-calls: 1

logging:
  level:
    com.berdachuk.medexpertmatch: DEBUG
    org.springframework.ai: DEBUG
    org.springframework.jdbc: DEBUG
    com.berdachuk.medexpertmatch.graph: DEBUG
